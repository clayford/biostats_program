---
title: "Statistical Methods in R"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---


## Agenda

- review of hypothesis testing and confidence intervals
- linear model basics
- odds and odds ratios
- logistic regression basics
- survival analysis basics

That's a lot for 2 hours!

## Load data and packages

```{r}
library(tidyverse)
```


Today we'll continue working with the following data:

Jung, Su-Young J et al. (2019), Data from: Phosphate is a potential biomarker of disease severity and predicts adverse outcomes in acute kidney injury patients undergoing continuous renal replacement therapy, Dryad, Dataset, https://doi.org/10.5061/dryad.6v0j9

```{r}
d <- readRDS('crrt.rds')
```

The study endpoint was _death that occurred within 28 and 90 days of continuous renal replacement therapy (CRRT) initiation_. CRRT is used to provide renal support for critically ill patients with acute kidney injury (AKI). We are interested in whether or not patients died within 28 or 90 days, and if so, how long did they survive with CRRT. This is contained in the `Death_*D` and `time_to_death_*D` variables.

```{r}
summary(d$Death_90D)
```

```{r}
summary(d$time_to_death_90D)
hist(d$time_to_death_90D)
```


## Hypothesis testing

Usually used to assess if two statistical measures are likely different, or if some statistic is likely different from 0. For comparing two groups, it's usually stated like so:

- Null: no difference in groups
- Alternative: groups are different

This is called a _two-sided_ test since our alternative does not specify which group is less than or more than the other. 

Example: Compare proportion of 90 day survivors and non-survivors with myocardial infarction.

```{r}
xtabs(~ Death_90D + MI, data = d) %>% 
  proportions(margin = 1) %>% 
  round(2) 
```

About 11% of survivors experienced MI versus 9% of non-survivors. What is the probability we observe a difference as big or bigger than 0.02 if there really is no difference in the entire population?

The answer is a _p-value_. We get the p-value using a hypothesis test. In this case we want to use a 2-sample proportion test with a two-sided alternative.

## 2-sample proportion test in R

We use `prop.test` function. It requires the number of "successes" (ie, event of interest) and the number of "trials" (ie, total number in each group).

Let's use `xtabs` and `addmargins` to get counts and row totals:

```{r}
xtabs(~ Death_90D + MI, data = d) %>% 
  addmargins()
```

Now we can use those values with `prop.test`:

```{r}
prop.test(x = c(76, 36), n = c(821, 323))
```

## Interpreting the test results

The p-value is about 0.39. If the proportion of survivors and non-survivors with MI truly was equal, this result is not unexpected. There's about a 39% chance of getting two proportions as different as these (or more different).

We could say, "with the current sample size the data were unable to overcome the supposition of no difference in the proportions." 

The 95% confidence interval is (-.06, 0.02). We're not sure of the magnitude or direction of the difference.

More about confidence intervals shortly.

## Chi-square test

Another way to compare two proportions is with a chi-square test of association. From the previous example, the null hypothesis is no association between survivor status and MI. Notice the p-value is identical to what we got with `prop.test`. In fact the math is exactly the same. 

```{r}
xtabs(~ Death_90D + MI, data = d) %>% 
  chisq.test()
```

The result of the `prop.test` function is more informative about how the proportions may differ. 

## Comparing our results with Table 1

The p-value reported for this comparison in Table 1 of the article is 0.20. Why is that? Apparently their hypothesis was as follows:

- Null: no difference in proportions
- Alternative: non-survivors less than survivors

To replicate their result we specify `alternative = "less"`

```{r}
prop.test(x = c(76, 36), n = c(821, 323), alternative = "less")
```

This test is making a stronger alternative assumption that the proportion of non-survivors with MI is _less than_ the proportion of survivors with MI.

Editorial: The article does not explain why they used this alternative. I'm surprised they used it. Usually Table 1 comparisons use the more conservative two-sided alternative. It is important to note that you _DO NOT_ pick the alternative based on the observed proportions!

## More hypothesis tests

Base R has a number of hypothesis test functions. Here are a few:

- `prop.test`: compare two proportions
- `chisq.test`: association between categorical variables
- `t.test`: compare two means
- `aov`: compare more than two means
- `cor.test`: linear association between numeric variables
- `wilcox.test`: compare ranks between two groups
- `kruskal.test`: compare ranks between more than two groups

Much could be said about the theory and assumptions of these tests. We don't have time to do that. Besides most research questions require more sophisticated statistical approaches that allow us to incorporate multiple variables or predictors. 

However here's one more example.

## Correlation test

From the article: "Phosphate level significantly correlated with the APACHE II (P < 0.001) and SOFA (P < 0.001) scores."

APACHE II and SOFA scores are measures of disease severity.

Correlation summarizes the strength and direction of a linear relationship and ranges from -1 to 1. A correlation test tests the null hypothesis that the correlation is different from 0.

```{r}
cor.test(d$P_0h, d$APA_II_CRRT_0h)
```

The paper simply reports the p-value of this test is less than 0.001. 

Editorial: I think it would have been more instructive to report the estimated correlation and confidence interval: 0.18 [0.12, 0.24]. A scatterplot makes this "significant" correlation appear much less significant.

```{r}
ggplot(d) +
  aes(x = P_0h, y = APA_II_CRRT_0h) +
  geom_point() +
  geom_smooth()
```


## Complaints about hypothesis testing

- implausible null hypotheses
- encourages researchers to engage in dichotomous thinking and downplay
  uncertainty and nuance
- misinterpretation of the p-value
    - the probability that the null hypothesis is true **(FALSE)**
    - the probability that the alternative hypothesis is NOT true **(FALSE)** 
    - smaller p-values mean bigger effects **(FALSE)**
    
## Confidence intervals

A statistic calculated from a sample is just an estimate. Another sample will almost certainly yield a different estimate. A confidence interval gives us some understanding of how uncertain we are about the estimate.

Confidence intervals are _not probability intervals_. 

The "confidence" is in the theoretical process:

1. sample data
2. calculate a 95% confidence interval
3. repeat steps 1 and 2 many times.
4. about 95% of the confidence intervals will contain the "true" value

Quick demo: sample 30 obs from a Normal distribution with mean 25 and SD 3, calculate the 95% confidence interval, repeat 1000 times, and determine proportion of times the CI captures the true value.

```{r}
# sample 30 obs from a Normal distribution with mean 25 and SD 3
x <- rnorm(n = 30, mean = 25, sd = 3)
# use t.test function to get 95% CI and save
t.out <- t.test(x)
# extract CI and see if it contains the true mean of 25
t.out$conf.int[1] < 25 & t.out$conf.int[2] > 25
```

We can do this 1000 times with the `replicate` function and save the results. We use `{}` to capture more than one line of code. 

```{r}
results <- replicate(1000, expr = {
  x <- rnorm(n = 30, mean = 25, sd = 3)
  t.out <- t.test(x)
  t.out$conf.int[1] < 25 & t.out$conf.int[2] > 25})

# mean of TRUE/FALSE (1,0) is proportion of TRUEs
mean(results)
```

The point is that 95% confidence intervals either do or do not contain the "true" value. The process results in CIs capturing the value about 95% of the time.

BTW, there's nothing special about "95%". _That's just tradition._ 

Confidence intervals quantify uncertainty and tell us about _the magnitude and direction_ of an effect in the context of a hypothesis test.

## CI Example

The article reports a significant difference in mean APACHE II scores between survivors and non-survivors (Table 1). However it does not report a confidence interval on the difference in means. We can replicate this using the `t.test` function. 

```{r}
t.test(APA_II_CRRT_0h ~ Death_90D, data = d)
```

Notice the confidence interval is (-4.3, -2.2). We're pretty confident the mean difference is somewhere in that range. 

Note: The internet tells us that "The APACHE II score ranges from 0 to 71 points; however, it is rare for any patient to accumulate more than 55 points." 

## Linear Model basics

Linear models, or multiple regression, allow us to estimate means _conditional on one or more predictors_. For example, Table 1 tells us the overall mean APACHE II score is 27.2

_Conditional mean_ APACHE II scores given survivor status:

survivors: 25.0
non-survivors: 28.2

We can keep adding conditions.

_Conditional mean_ APACHE II score given survivor status is Non-survivor and age is 50: 27.3

_Conditional mean_ APACHE II score given survivor status is Non-survivor and age is 60: 28.0

Conditioning on a variable may not give appreciably different means. Or put another way, the variable may not be a significant predictor.

T-tests, ANOVAs, and ANCOVAs are all special cases of linear regression.

Whole books are devoted to linear regression. This is a very brief intro!

## Linear regression example

From the article: "In a multivariable linear regression analysis after adjustment for age, sex, CCI, MAP, and urine volume, phosphate levels were significantly associated with the SOFA (beta = 0.10, P = 0.02) and APACHE II (beta = 0.58, P < 0.001) scores (Table 2)"

Let's replicate the SOFA analysis using the `lm` function. The formula for this model is `SOFA_CRRT_0h ~ Age + Sex + CCI + MAP_0h + UO_2hrs + P_0h`. This basically says "we (the authors) think the SOFA score is a weighted sum of age, sex, CCI, MAP, urine volume, and phosphate levels."

```{r}
m1 <- lm(SOFA_CRRT_0h ~ Age + Sex + CCI + MAP_0h + UO_2hrs + P_0h, data = d)
summary(m1)
```

The Estimates column in the Coefficients section are the "betas". They are the weighted sums in an additive formula. These values match what are in Table 2 (the multivariate column for the SOFA section).

The P_0H coefficient (or beta) is 0.10. That says "each additional unit of Phosphate produces an increase of 0.10 in the SOFA mean score, assuming all else held constant." Note: The SOFA score ranges from 0 to 24.

Let's say we have two subjects with following values. Notice they are identical except for Phosphate (P_0h).

```{r}
sub1 <- data.frame(Age = 50, Sex = "Female", CCI = 3, 
          MAP_0h = 77, UO_2hrs = 30, P_0h = 4)
sub2 <- data.frame(Age = 50, Sex = "Female", CCI = 3, 
          MAP_0h = 77, UO_2hrs = 30, P_0h = 5)
```

We can use the `predict` function to get expected mean values for our subjects using our model. 

The expected mean SOFA score for subject 1:

```{r}
predict(m1, newdata = sub1)
```

Expected mean APACHE II score for subject 2:

```{r}
predict(m1, newdata = sub2)
```

The difference between the expected means is the same as the Phosphate coefficient (0.103703):

```{r}
predict(m1, newdata = sub2) - predict(m1, newdata = sub1)
```

The p-value of 0.02 associated with the Phosphate coefficient is for the null hypothesis test that the coefficient is equal to 0. We have evidence that Phosphate seems to have a small effect on the APACHE II score. 

The predictions are subject to uncertainty. We can get a confidence interval by specifying `interval = "confidence"`

```{r}
predict(m1, newdata = sub1, interval = "confidence")
```

The Adjusted R-squared is 0.06595. R-squared ranges from 0 to 1 and gives us some indication of the amount of variability our model explains. This says our linear regression model explains about 7% of the variability in the APACHE II score. Not great.

One way to check the fit of our model is to plot residuals versus fitted values. In this case residuals are the differences in the _observed_ SOFA score and what the model _predicts_. We can do that by calling `plot` on our model object and specifying `which = 1`.

```{r}
plot(m1, which = 1)
```

The plot shows us...

- most predicted values are between 10 and 14.
- The amount the model is off in either direction is fairly constant, about -10 to 10. (the constant variance is good)
- points above 0 are those observations for which the model under-predicts (the SOFA values are _higher_ than the model predicts)
- points below 0 are those observations for which the model over-predicts (the SOFA values are _lower_ than the model predicts)

Reacll SOFA scores range from 0 to 24. A model with conditional means that are systematically "off" by 5 or 10 points is perhaps not great.


## Odds and Odds Ratios

Odds ratios are frequently used in medical research. They often arise in the context of logistic regression, which is used to model the probability of an event given one or more predictors.

Odds are a function of probability.

$$O = \frac{p}{(1 - p)} $$
If p = 0.75, then the odds are 3 to 1.

```{r}
0.75/(1 - 0.75)
```

That's 3 successes for every failure.

If p = 0.25, then the odds are 3 to 1 against, or 1/3.

```{r}
0.25/(1 - 0.25)
```

That's 1 success for every 3 failures.

Notice odds are positive and can range from [0, infinity) unlike probability which ranges [0,1].

**Odds ratios** are simply the ratio of two odds.


## Odds ratio example

Earlier we compared the proportions of survivors and non-survivors with myocardial infarction. Recall the proportions were 0.11 versus 0.09. That's a difference of 0.02. That's usually called _risk difference_. We could also compare their odds using odds ratios.

```{r}
tab <- xtabs(~ Death_90D + MI, data = d) %>% 
  proportions(margin = 1)
tab
```

Let's get the odds using the odds formula.

```{r}
surv_odds <- tab[1,2]/(1 - tab[1,2])
death_odds <- tab[2,2]/(1 - tab[2,2])
round(c(surv_odds, death_odds), 2)
```

The odds ratio:

```{r}
death_odds/surv_odds
```

It appears the odds of dying within 90 days after CRRT is about 19% lower for those who experienced myocardial infarction versus those who did not! But this is just a point estimate. We should calculate a confidence interval for the odds ratio. There are many ways to go about doing this. The most common way is in the context of _logistic regression_.


## Logistic regression

Logistic regression is like linear regression but for binary variables (0/1, T/F, succeed/fail, live/die, etc). Instead of predicting conditional means, it _predicts conditional probabilities_ of events.

For example, some subjects died within 90 days of continuous renal replacement therapy (CRRT) initiation, but others did not. Logistic regression could be used to model the _probability of surviving_ beyond 90 days as a function of Phosphate levels, age, sex, and other predictors. 

Whole books are devoted to logistic regression. This is a very brief intro!

## Logistic regression example

Earlier we estimated the odds of dying within 90 days after CRRT is about 19% lower for those who experienced myocardial infarction versus those who did not. We can get this same estimate using logistic regression.

We use the `glm` function, which stands for "generalized linear model". We specify `family = binomial` since our response variable is binary. The summary output looks similar to linear regression output, but the coefficients are on the _logit_ scale, or log odds. 

```{r}
m2 <- glm(Death_90D ~ MI, data = d, family = binomial)
summary(m2)
```

If we exponentiate the coefficients we get odds ratios.

```{r}
exp(coef(m2))
```

And if we use the `confint` function we can get a confidence interval for the odds ratio.

```{r}
exp(confint(m2))

```

The CI is (0.54, 1.25). The CI on the MI odds ratio overlaps 1 by a wide margin in both directions. (Recall a ratio of 1 is the same as equal odds.) We're not sure what effect having a MI has on the probability of dying within 90 days after CRRT. 

The Intercept is the log-odds of dying without MI. The MI coefficient is the change in log-odds of dying if one had a MI.

To get predicted probabilities of dying, use `predict` with `type="response"`.

```{r}
predict(m2, newdata = data.frame(MI = 0:1), type = "response")
```


## Odds ratios obscure differences in probabilities

A drawback of odds ratios is that they obscure the difference in probabilities.

Here's an odds ratio of about 9 that reflects an increase from 0.001 to 0.009. 

```{r}
(0.009/(1 - 0.009)) /
  (0.001/(1 - 0.001))
```

Here's another odds ratio of about 9 that reflects an increase from 0.07 to 0.40.

```{r}
(0.4/(1 - 0.4)) /
  (0.07/(1 - 0.07))

```

_An odds ratio of 9 by itself doesn't tell us about absolute risk_. Increasing the risk of illness from 0.001 to 0.009 may not be as concerning as increasing the risk of illness from 0.07 to 0.40.

Carefully consider all statistics. 


## Survival analysis basics

Survival analysis is the analysis of data on _the time until occurrence of a specific event_. Example: time to death within 90 days of CRRT initiation. 

The term "survival" is used because the event of interest is often (sadly) death. Survival analysis is a field unto itself. I can't do it justice in this little presentation!

We use survival analysis to estimate _the probability that a subject does not experience the event until some time_. Example: Probability a subject survives at least 60 days after CRRT initiation.

An important feature of survival analysis data is that it usually contains "incomplete" or _censored_ data. These are subjects that _do not_ experience the event of interest. Example: some subjects (thankfully) survive beyond 90 days after CRRT. However we can make use of their data. To exclude them would _bias_ our probability estimates, which is a fancy way of saying it would make our estimates wrong. 

Two things usually done with survival analysis:

- Estimated survival curves using the _Kaplan-Meier method_
- Model survival time using _Cox proportional hazards model_

A survival curve plots probability of surviving over time. The Cox proportional hazards model is like linear regression for survival time.

## Survival analysis example: Kaplan-Meier

From the article: "A Kaplan-Meier curve also confirmed that time to death was significantly shorter in patients with increased phosphate levels (Fig 3)."

Figure 3 shows survival curves for 3 groups:

- Group 1 (phosphate decrease group), less than -1.3 mg/dL
- Group 2 (stable group), -1.3 to 0 mg/dL
- Group 3 (phosphate increase group), greater than 0 mg/dL

These groups are not in the data as a variable and must be _derived_ using the `Delta_P` variable (phosphate change). We can do that using the base R `cut` function. Below we create a new categorical variable called `p_change` that has three groups according to the definition above. 
 
The `breaks = c(-Inf, -1.3, 0, Inf)` argument specifies the boundaries of our groups. `-Inf` and `Inf` are R keywords that mean negative infinity and positive infinity, respectively. Four boundaries implies three groups (right inclusive):

- (-Inf, -1.3]
- (-1.3, 0]
- (0, Inf)
 
```{r}
d <- mutate(d, p_change = cut(Delta_P, 
                              breaks = c(-Inf, -1.3, 0, Inf), 
                              labels = c("Group 1", "Group 2", "Group 3")))
xtabs(~ p_change, data = d, subset = Death_90D == "Yes")
```

Now we can create the Kaplan-Meier survivor curves for the three groups. This plots the _estimated probability of surviving over time_. To do this we'll use the `survfit` function that's part of the survival package that comes with R.

The `survfit` function creates survival curves using model notation similar to `lm` and `glm`. In this case we want to model `time_to_death_90D` as a function of `p_change`, the grouping variable we just created. The only difference is we need to create a _survival object_ for our response variable using the `Surv` function. It takes two arguments: 

1. the variable we're modeling (`time_to_death_90D`) and,
2. the condition that defines the event of interest (`Death_90D=="Yes"`).

```{r}
library(survival)
surv.group <- survfit(Surv(time_to_death_90D, Death_90D=="Yes") ~ p_change,
                      data = d)
surv.group
```

The median time to death for Group 3 (phosphate increase) was 2 days with a 95% CI of (1.6, 3.0).

Now we can create the plot by calling `plot` on the surv.group object we created. Note: we need to run the entire chunk of code.

```{r}
plot(surv.group, lty = 1:3, xlab = "Days", ylab = "Proportion survival")
legend("topright",c("Group 1", "Group 2", "Group 3"), lty = 1:3) 

```

To create a ggplot version you can use the survminer package.

```{r}
# install.packages("survminer")
library(survminer)
ggsurvplot(surv.group) +
  labs(x = "Days", y = "Proportion survival")

```


The Phosphate increase group (Group 3) has about a 30% chance of survival to 20 days.

Is there a difference in the survival curves? We can use the _log-rank test_ to assess this by way of the `survdiff` function. The null hypothesis is no difference in survival curves. A small p-value provides evidence against the null hypothesis.

```{r}
survdiff(Surv(time_to_death_90D, Death_90D=="Yes") ~ p_change,
         data = d)
```

The p-value is reported as 1e-04, or 0.0001. We have good evidence the survival curves are indeed different.

Figure 3 in the paper shows _pairwise comparisons_ between the curves. The results can be replicated by simply subsetting data to compare two groups at a time. For example, Group 1 versus Group 2:

```{r}
survdiff(Surv(time_to_death_90D, Death_90D=="Yes") ~ p_change,
         data = d, subset = p_change != "Group 3")
```


## Survival analysis example: Cox proportional hazards model

The paper states "To delineate the association between phosphate and mortality, we constructed stepwise multivariable Cox models. In all three models, phosphate levels were significantly associated with an increased risk of death. The fully adjusted model (model 3) revealed that the HRs for 90-day mortality was 1.05 (per 1 mg/dL increase, 95% CI, 1.02–1.08; P = 0.001) (Table 3)."

_Stepwise_ is a form of variable selection that automatically finds the "best" model given lots of candidate predictors. It is frowned upon by many statisticians for many reasons.

HR means _hazard ratio_. A hazard ratio measures how often an event happens in one group compared to how often it happens in another group, over time. A hazard ratio of 1.05 suggests that every one unit increase in phosphate level is associated with 5% increase in the risk of death.

_The fully adjusted model_, or Model 3, includes phosphate level, age, sex, BMI at ICU admission, CCI, SOFA score, and urine output. (Model 1 just included phosphate; Model 2 included phosphate, age, sex and BMI.) 

Let's replicate this analysis and compare to Table 3.

```{r}
coxm <- coxph(Surv(time_to_death_90D, Death_90D=="Yes") ~ P_0h + 
                Age + Sex + BMI_ICU + CCI + 
                SOFA_CRRT_0h + UO_2hrs, data = d)
summary(coxm)

```

The second section contains the hazard ratios, which can be obtained by exponentiating the model coefficients.


